# -*- coding: utf-8 -*-
"""Diabetes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZFpkCAlCfJdBLNfEGidyDxhyePN_zlfw
"""

import numpy as np
import pandas as pd
from tkinter.filedialog import askopenfilename
from sklearn.model_selection import train_test_split
from sklearn import preprocessing
from sklearn.model_selection import KFold
from sklearn.linear_model import LinearRegression
from sklearn.metrics import average_precision_score
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_log_error
from sklearn.neighbors import KNeighborsClassifier
np.random.seed(3)
def avg_age(ser):
    list_of_list = list()
    list_of_num = list()
    for a in ser:
        a = list(a)
        for i in a:
            if i == '[' or i == '-' or i == ')':
                a.remove(i)
            if '[' not in a and '-' not in a and ')' not in a:
                if len(a) == 3:
                    a[1] = a[1]+ a[2]
                    a.pop(2)
                    a[0] = int(a[0])
                    a[1] = int(a[1])
                    a[0] = int((a[0]+a[1])/2)
                    a.pop(1)
                if len(a) == 4:
                    a[0] = a[0] + a[1]
                    a[1] = a[2] + a[3]
                    a.pop(2)
                    a.pop(2)
                    a[0] = int(a[0])
                    a[1] = int(a[1])
                    a[0] = int((a[0]+a[1])/2)
                    a.pop(1)
                if len(a) == 5:
                    a[0] = a[0] + a[1]
                    a[1] = a[2] + a[3] + a[4]
                    a.pop(2)
                    a.pop(2)
                    a.pop(2)
                    a[0] = int(a[0])
                    a[1] = int(a[1])
                    a[0] = int((a[0]+a[1])/2)
                    a.pop(1)
        list_of_list.append(a)
    for ele in list_of_list:
        ele = int(ele[0])
        zero = np.zeros((6), dtype=int)
        zero[0] = ele
        list_of_num.append(zero)
    new_ser = pd.Series((list_of_num))
    return new_ser

def convert_one_hot(ser,num_parameters):
    list_of_array = list()
    if num_parameters == 4:
        for a in ser:
            one_hot = np.zeros((6), dtype=int)
            if a == 'No':
                one_hot[0] = 1
                list_of_array.append(one_hot)
                continue
            elif a == 'Down':
                one_hot[1] = 1
                list_of_array.append(one_hot)
                continue
            elif a == 'Steady':
                one_hot[2] = 1
                list_of_array.append(one_hot)
                continue
            elif a == 'Up':
                one_hot[3] = 1
                list_of_array.append(one_hot)
                continue
    if num_parameters == 6:
        for a in ser:
            one_hot = np.zeros((6), dtype=int)
            if a == '?':
                one_hot[0] = 1
                list_of_array.append(one_hot)
                continue
            elif a == 'AfricanAmerican':
                one_hot[1] = 1
                list_of_array.append(one_hot)
                continue
            elif a == 'Asian':
                one_hot[2] = 1
                list_of_array.append(one_hot)
                continue
            elif a == 'Caucasian':
                one_hot[3] = 1
                list_of_array.append(one_hot)
                continue
            elif a == 'Hispanic':
                one_hot[4] = 1
                list_of_array.append(one_hot)
                continue
            else:
                one_hot[5] = 1
                list_of_array.append(one_hot)
                continue
    if num_parameters == 3:
        for a in ser:
            one_hot = np.zeros((num_parameters), dtype=int)
            if a == 'NO':
                one_hot[0] = 1
                list_of_array.append(one_hot)
                continue
            elif a == '>30':
                one_hot[1] = 1
                list_of_array.append(one_hot)
                continue
            elif a == '<30':
                one_hot[2] = 1
                list_of_array.append(one_hot)
                continue        
    new_ser = pd.Series((list_of_array))
    return new_ser

def one_hot_for_num(ser):
    list_of_array = list()
    for ele in ser:
        array = np.zeros((6),dtype=int)
        array[0] = ele
        list_of_array.append(array)
    new_ser = pd.Series((list_of_array))
    return new_ser
        

def execute(name,col_num=12):
    global raw_data
    ser = convert_one_hot(raw_data[name],4)
    raw_data = raw_data.drop(name,axis =1)
    raw_data.insert(col_num, name, ser, True)
    return raw_data[name]

def execute_num(name,col_num=12):
    global raw_data
    ser = one_hot_for_num(raw_data[name])
    raw_data = raw_data.drop(name,axis =1)
    raw_data.insert(col_num, name, ser, True)
    return raw_data[name]

def concat_one_hot_vectors(row_ser):
    list_of_vectors = list()
    for ele in row_ser:
        list_of_vectors.append(ele)
    vector = np.concatenate(list_of_vectors)
    return vector

def execute_concat_one_hot_vectors(data):
    list_of_vectors = list()
    for num in range(len(data)):
        final_vectors = concat_one_hot_vectors(data.iloc[num])
        list_of_vectors.append(final_vectors)
    return list_of_vectors
def convert_pred_to_one_and_zeros(arr):
    list_of_val = list()
    vector = np.zeros(3)
    max1 = np.argmax(arr)
    vector[max1] = 1 
    return vector

from google.colab import files
uploaded = files.upload()

#from google.colab import files
import io
file = 'C:/Users/DivyanshJain/Desktop/Divyansh/Datasets/dataset_diabetes/diabetic_data.csv' #Ask user for a file
# print(str(uploaded)[2:100])
raw_data = pd.read_csv(io.BytesIO(uploaded['diabetic_data.csv']))
raw_data.head(10)

raw_data = raw_data.drop(['encounter_id','patient_nbr','payer_code',
                          'medical_specialty','weight','admission_type_id','discharge_disposition_id',
                          'admission_source_id', 'payer_code','medical_specialty','number_outpatient',
                          'number_emergency','number_inpatient','diag_1','diag_2',
                          'diag_3','max_glu_serum','A1Cresult'],axis=1)


age_ser = avg_age(raw_data['age'])
raw_data = raw_data.drop('age',axis =1)
raw_data.insert(2, "age", age_ser, True)
#print(raw_data['age'])
print(raw_data.head(10))

column_names = ['metformin','repaglinide','nateglinide','chlorpropamide',
                'glimepiride','acetohexamide','glipizide','glyburide',
                'tolbutamide','pioglitazone','rosiglitazone','acarbose',
                'miglitol','troglitazone','tolazamide','examide',
                'citoglipton','insulin','glyburide-metformin','glipizide-metformin',
                'glimepiride-pioglitazone','metformin-rosiglitazone','metformin-pioglitazone']
column_names_num = ['time_in_hospital', 'num_lab_procedures', 'num_procedures', 'num_medications', 'number_diagnoses']

for names in column_names:
    execute(names)
for names in column_names_num:
    execute_num(names)
#convert race into one hot vectors
race = convert_one_hot(raw_data['race'],6)
raw_data = raw_data.drop('race',axis =1)
raw_data.insert(0, 'race', race, True)

#convert readmitted to one hot vectors
readm = convert_one_hot(raw_data['readmitted'],3)
raw_data = raw_data.drop('readmitted',axis =1)
raw_data.insert(0, 'readmitted', readm, True)

#Binary changes in the data
change_gender = {'Female':np.array([0,0,0,0,0,0]), 'Male':np.array([0,1,0,0,0,0]), 'Unknown/Invalid':np.array([0,0,1,0,0,0])}
change_change = {'Ch':np.array([0,1,0,0,0,0]), 'No':np.array([0,0,0,0,0,0])}
change_meds = {'No':np.array([0,0,0,0,0,0]), 'Yes':np.array([0,1,0,0,0,0])}

#Implementing the changes
raw_data.gender = raw_data.gender.map(change_gender)
raw_data.change = raw_data.change.map(change_change)
raw_data.diabetesMed = raw_data.diabetesMed.map(change_meds)
#This is where you concat the one hot vectors
data = raw_data.drop(['readmitted'],axis=1)
#print(data.iloc[30506])
#index = list(range(30506,101766,1))
#data = data.drop(index,axis=0)
#print(data)
data = execute_concat_one_hot_vectors(data)
data = np.array(data)
print('shape:',data.shape)
labels = raw_data['readmitted']
#labels = labels.drop(index, axis=0)
labels = labels.to_numpy()
list_out = list()
#This changes labels into a 2D array
for ele in labels:
    list_out.append(ele)
labels = np.array(list_out)

print('xshape:',data.shape)
#Make all the classes have the same amount of data
list_of_index_g30 = list()
list_of_index_no = list()
list_of_index_l30 = list()
for num in range(len(labels)):
  if len(list_of_index_g30) < 11357:
    if np.array_equal(labels[num],np.array([0,1,0])):
      list_of_index_g30.append(num)
  if len(list_of_index_no) < 11357:
    if np.array_equal(labels[num],np.array([1,0,0])):
      list_of_index_no.append(num)
  if len(list_of_index_l30) < 11357:
    if np.array_equal(labels[num],np.array([0,0,1])):
      list_of_index_l30.append(num)
  
print('>30:',len(list_of_index_g30))
print('NO:',len(list_of_index_no))
print('<30:',len(list_of_index_l30))
index = list_of_index_g30 + list_of_index_no + list_of_index_l30
print('index:',type(index))
#Deleting elements from the array by index
list_of_array_l = list()
list_of_array_d = list()
for num in range(len(labels)):
  if num in index:
    list_of_array_l.append(labels[num])
    list_of_array_d.append(data[num])
labels = np.array(list_of_array_l)
data = np.array(list_of_array_d)      
    
no = 0
greater_30 = 0
less_30 = 0
for ele in labels:
  if np.array_equal(ele,np.array([1,0,0])) == True:
    no = no + 1
  if np.array_equal(ele,np.array([0,1,0])) == True:
    greater_30 = greater_30 + 1
  if np.array_equal(ele,np.array([0,0,1])) == True:
    less_30 = less_30 + 1
print('NO:',no)
print('>30:',greater_30)
print('<30:',less_30)
#Train test validation split
X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)
X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.25, random_state=42)
no = 0
greater_30 = 0
less_30 = 0
for ele in y_test:
  if np.array_equal(ele,np.array([1,0,0])) == True:
    no = no + 1
  if np.array_equal(ele,np.array([0,1,0])) == True:
    greater_30 = greater_30 + 1
  if np.array_equal(ele,np.array([0,0,1])) == True:
    less_30 = less_30 + 1
print('NO:',no/6815)
print('>30:',greater_30/6815)
print('<30:',less_30/6815)
print("x_train:",X_train.shape)
print("y_train:",y_train.shape)
print("x_train:",X_train[0])
print("y_train:",y_train)
print("x_valid:",X_valid.shape)
print("y_valid:",y_valid.shape)
print("x_test:",X_test.shape)
print("y_test:",y_test.shape)

##Linear Regression Model
model = LinearRegression().fit(X_train, y_train)
preds = model.predict(X_valid)
count = 0
for i in range(len(y_valid)):
    new_vector = convert_pred_to_one_and_zeros(preds[i])
    #print(new_vector)
    if np.array_equal(y_valid[i],new_vector) == True:
        count = count + 1
accuracy = (count/len(y_valid))*100

print('Baseline Accuracy:',accuracy,'%')

#K-NN Model
#Hyper parameters
K = 1
model = KNeighborsClassifier(n_neighbors=K)
model.fit(X_train, y_train)
preds = model.predict(X_valid)
count = 0
for i in range(y_valid.shape[0]):
    new_vector = convert_pred_to_one_and_zeros(preds[i])
    #print(new_vector)
    if np.array_equal(y_valid[i],new_vector) == True:
        count = count + 1

accuracy = (float(count)/float(len(y_valid)))*100
print('Accuracy:',accuracy,'%')

#Neural Network
import tensorflow as tf
from keras.models import Sequential
from keras.layers.core import Dense, Activation, Flatten, Dropout
from keras.callbacks import EarlyStopping
from keras.optimizers import RMSprop
from keras.layers import Conv1D, MaxPooling1D
from keras.optimizers import SGD
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn.metrics import roc_auc_score

model=Sequential()
model.add(Dense(100, activation='sigmoid', use_bias = True))
model.add(Dense(100, activation='sigmoid', use_bias = True))
model.add(Dense(10, activation='sigmoid', use_bias = True))
model.add(Dense(10, activation='sigmoid', use_bias = 2))
model.add(Dense(5, activation='sigmoid', use_bias=10))
model.add(Dense(3, activation='softmax'))
model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])
early_stopping = EarlyStopping(monitor='loss', patience=1.99, mode='min')
history = model.fit(X_train, y_train, batch_size=64, epochs=100, verbose=1, validation_data= None,callbacks=[early_stopping])

from keras.models import model_from_json

model_json = model.to_json()
with open("model.json", "w") as json_file:
    json_file.write(model_json)

model.save_weights("weights4.h5")

#Validating on the validation set
loss, acc = model.evaluate(X_valid, y_valid)
y_pred = model.predict(X_valid)
print(X_valid.shape)
list_of_vector = list()

for ele in y_pred:
  vector = convert_pred_to_one_and_zeros(ele)
  list_of_vector.append(vector)
y_pred = np.array(list_of_vector)
print('Validation Loss:', loss)
print('Validation Accuracy:',acc*100,'%')
print(model.summary())

#Confusion Matrix Validation
import sklearn.metrics as skm
import seaborn as sn
import pandas as pd
import matplotlib.pyplot as plt
#cm = skm.multilabel_confusion_matrix(y_valid, y_pred)
print('Validation Confusion Matrix in respect two classes')
cm = multilabel_confusion_matrix(y_valid, y_pred)
array = cm[0]       
df_cm = pd.DataFrame(array, range(2),
                  range(2))
sn.set(font_scale=1)#for label size
sn.heatmap(df_cm, annot=True,annot_kws={"size": 30})# font size

#Testing on test data to see how it would perform in the wild
loss, acc = model.evaluate(X_test, y_test)
y_preds = model.predict(X_test)
list_of_vector = list()
for ele in y_preds:
  vector = convert_pred_to_one_and_zeros(ele)
  list_of_vector.append(vector)
y_pred1 = np.array(list_of_vector)
print('Testing Loss:',loss)
print('Testing Accuracy:',acc*100,'%')

#Confusion Matrix Testing
import sklearn.metrics as skm
import seaborn as sn
import pandas as pd
import matplotlib.pyplot as plt
print('Testing Confusion Matrix in respect two classes')
cm = multilabel_confusion_matrix(y_test, y_pred1)
array = cm[1]       
df_cm1 = pd.DataFrame(array, range(2),
                  range(2))
sn.set(font_scale=1)#for label size
sn.heatmap(df_cm1, annot=True,annot_kws={"size": 30})# font size

